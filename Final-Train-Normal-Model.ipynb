{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:38:44.999202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:45.009061: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:45.009927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asl_model import *\n",
    "\n",
    "TRAIN_DIR = 'DATASET_A_AP/train'\n",
    "TEST_DIR = 'DATASET_A_AP/test'\n",
    "\n",
    "BATCH = 128\n",
    "EPOCH = 100\n",
    "\n",
    "model_func = get_model_1\n",
    "\n",
    "checkpoint_path = \"ckpt_normal_training/cp.ckpt\"\n",
    "tb_log_dir = 'normal-logs/'\n",
    "entire_model_s_path = 'saved_model/normal_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert folder to dataframe of images' paths & labels\n",
    "def get_paths_labels(path, allowed_extension=\"jpg\"):\n",
    "        global Path\n",
    "        images_dir = Path(path)\n",
    "        \n",
    "        filepaths = pd.Series((images_dir.glob(fr'**/*.{allowed_extension}'))).astype(str)\n",
    "        filepaths.name = \"path\"\n",
    "        \n",
    "        labels = filepaths.str.split(\"/\")[:].str[-2]\n",
    "        labels.name = \"label\"\n",
    "\n",
    "        # Concatenate filepaths and labels\n",
    "        df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "        # Shuffle the DataFrame and reset index\n",
    "        df = df.sample(frac=1).reset_index(drop = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_paths_labels(TRAIN_DIR)\n",
    "test_df = get_paths_labels(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46174 validated image filenames belonging to 26 classes.\n",
      "Found 11543 validated image filenames belonging to 26 classes.\n",
      "Found 14430 validated image filenames belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=0.2,\n",
    "                                    rescale=1. / 255.,\n",
    "                                    zoom_range=0.1,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.1,)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1. / 255.)\n",
    "\n",
    "train_images = data_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = data_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    # batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"ckpt_normal_training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=2, \n",
    "    save_weights_only=True,\n",
    "    # save_best_only=True,\n",
    "    save_freq=5*BATCH\n",
    ")\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_log_dir, histogram_freq=1)\n",
    "\n",
    "callback_ls = [\n",
    "    es_callback, \n",
    "    reduce_lr_callback, \n",
    "    cp_callback,\n",
    "    tb_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = model_func()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:38:46.456116: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-23 01:38:46.457104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:46.457979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:46.458782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:46.921292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:46.921882: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:46.922421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:38:46.922944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9546 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:38:48.071391: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 23s 58ms/step - loss: 0.5690 - accuracy: 0.8327 - val_loss: 2.1054 - val_accuracy: 0.3393 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "278/361 [======================>.......] - ETA: 3s - loss: 0.1715 - accuracy: 0.9478\n",
      "Epoch 00002: saving model to ckpt_normal_training/cp.ckpt\n",
      "361/361 [==============================] - 21s 59ms/step - loss: 0.1646 - accuracy: 0.9498 - val_loss: 0.1477 - val_accuracy: 0.9548 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "361/361 [==============================] - 21s 58ms/step - loss: 0.1098 - accuracy: 0.9660 - val_loss: 0.1196 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "195/361 [===============>..............] - ETA: 7s - loss: 0.0834 - accuracy: 0.9749\n",
      "Epoch 00004: saving model to ckpt_normal_training/cp.ckpt\n",
      "361/361 [==============================] - 21s 58ms/step - loss: 0.0840 - accuracy: 0.9747 - val_loss: 0.1054 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "361/361 [==============================] - 21s 58ms/step - loss: 0.0729 - accuracy: 0.9778 - val_loss: 0.0798 - val_accuracy: 0.9763 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "113/361 [========>.....................] - ETA: 11s - loss: 0.0593 - accuracy: 0.9815\n",
      "Epoch 00006: saving model to ckpt_normal_training/cp.ckpt\n",
      "361/361 [==============================] - 21s 59ms/step - loss: 0.0635 - accuracy: 0.9800 - val_loss: 0.0919 - val_accuracy: 0.9705 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "361/361 [==============================] - 21s 58ms/step - loss: 0.0562 - accuracy: 0.9828 - val_loss: 0.0892 - val_accuracy: 0.9725 - lr: 0.0010\n",
      "Epoch 8/100\n",
      " 32/361 [=>............................] - ETA: 15s - loss: 0.0527 - accuracy: 0.9849\n",
      "Epoch 00008: saving model to ckpt_normal_training/cp.ckpt\n",
      "361/361 [==============================] - 21s 59ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.0600 - val_accuracy: 0.9824 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "311/361 [========================>.....] - ETA: 2s - loss: 0.0470 - accuracy: 0.9852\n",
      "Epoch 00009: saving model to ckpt_normal_training/cp.ckpt\n",
      "361/361 [==============================] - 22s 60ms/step - loss: 0.0466 - accuracy: 0.9852 - val_loss: 0.0481 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "361/361 [==============================] - 22s 61ms/step - loss: 0.0495 - accuracy: 0.9844 - val_loss: 0.0604 - val_accuracy: 0.9805 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "229/361 [==================>...........] - ETA: 6s - loss: 0.0415 - accuracy: 0.9867\n",
      "Epoch 00011: saving model to ckpt_normal_training/cp.ckpt\n",
      "361/361 [==============================] - 22s 61ms/step - loss: 0.0408 - accuracy: 0.9872 - val_loss: 0.0569 - val_accuracy: 0.9819 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "361/361 [==============================] - 21s 59ms/step - loss: 0.0399 - accuracy: 0.9868 - val_loss: 0.0718 - val_accuracy: 0.9776 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "146/361 [===========>..................] - ETA: 10s - loss: 0.0350 - accuracy: 0.9884\n",
      "Epoch 00013: saving model to ckpt_normal_training/cp.ckpt\n",
      "361/361 [==============================] - 21s 58ms/step - loss: 0.0389 - accuracy: 0.9873 - val_loss: 0.0490 - val_accuracy: 0.9858 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "361/361 [==============================] - 21s 58ms/step - loss: 0.0345 - accuracy: 0.9883 - val_loss: 0.0728 - val_accuracy: 0.9786 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9588e54b80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, \n",
    "          validation_data=val_images,\n",
    "          epochs=EPOCH,\n",
    "          callbacks=callback_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:43:47.540609: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/normal_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(entire_model_s_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(entire_model_s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 5s 10ms/step - loss: 0.5360 - accuracy: 0.8949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5359690189361572, 0.8948717713356018]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload weight by checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f95889aa370>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 5s 9ms/step - loss: 0.6393 - accuracy: 0.8863\n",
      "Restored model, accuracy: 88.63%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASLT",
   "language": "python",
   "name": "aslt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
