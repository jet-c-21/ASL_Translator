{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:17:17.423180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:17.428925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:17.429322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asl_model import get_model_3\n",
    "\n",
    "TRAIN_DIR = 'DATASET_A_AP/train'\n",
    "TEST_DIR = 'DATASET_A_AP/test'\n",
    "\n",
    "BATCH = 128\n",
    "EPOCH = 100\n",
    "\n",
    "model_func = get_model_3\n",
    "\n",
    "checkpoint_path = \"ckpt_app_training/cp.ckpt\"\n",
    "tb_log_dir = 'app-logs/'\n",
    "entire_model_s_path = 'saved_model/app_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert folder to dataframe of images' paths & labels\n",
    "def get_paths_labels(path, allowed_extension=\"jpg\"):\n",
    "        global Path\n",
    "        images_dir = Path(path)\n",
    "        \n",
    "        filepaths = pd.Series((images_dir.glob(fr'**/*.{allowed_extension}'))).astype(str)\n",
    "        filepaths.name = \"path\"\n",
    "        \n",
    "        labels = filepaths.str.split(\"/\")[:].str[-2]\n",
    "        labels.name = \"label\"\n",
    "\n",
    "        # Concatenate filepaths and labels\n",
    "        df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "        # Shuffle the DataFrame and reset index\n",
    "        df = df.sample(frac=1).reset_index(drop = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_paths_labels(TRAIN_DIR)\n",
    "test_df = get_paths_labels(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46174 validated image filenames belonging to 26 classes.\n",
      "Found 11543 validated image filenames belonging to 26 classes.\n",
      "Found 14430 validated image filenames belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=0.2,\n",
    "                                    rescale=1. / 255.,\n",
    "                                    zoom_range=0.1,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.1,)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1. / 255.)\n",
    "\n",
    "train_images = data_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = data_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    # batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"ckpt_normal_training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=2, \n",
    "    save_weights_only=True,\n",
    "    # save_best_only=True,\n",
    "    save_freq=5*BATCH\n",
    ")\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_log_dir, histogram_freq=1)\n",
    "\n",
    "callback_ls = [\n",
    "    es_callback, \n",
    "    reduce_lr_callback, \n",
    "    cp_callback,\n",
    "    tb_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asl_model import *\n",
    "\n",
    "def create_model():\n",
    "    model = get_model_3()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:17:18.965648: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-23 01:17:18.966474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:18.966870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:18.967207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:19.398226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:19.398586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:19.398905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:17:19.399216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2500 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:17:20.776240: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - ETA: 0s - loss: 1.8420 - accuracy: 0.5919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:17:46.064066: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 28s 71ms/step - loss: 1.8420 - accuracy: 0.5919 - val_loss: 4.2211 - val_accuracy: 0.1117 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "277/361 [======================>.......] - ETA: 4s - loss: 0.7297 - accuracy: 0.8169\n",
      "Epoch 00002: saving model to ckpt_app_training/cp.ckpt\n",
      "360/361 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.8301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:18:11.560152: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 26s 71ms/step - loss: 0.6715 - accuracy: 0.8303 - val_loss: 0.2896 - val_accuracy: 0.9295 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.8947"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:18:36.605649: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 25s 69ms/step - loss: 0.3850 - accuracy: 0.8947 - val_loss: 0.1915 - val_accuracy: 0.9540 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "196/361 [===============>..............] - ETA: 8s - loss: 0.2798 - accuracy: 0.9203\n",
      "Epoch 00004: saving model to ckpt_app_training/cp.ckpt\n",
      "360/361 [============================>.] - ETA: 0s - loss: 0.2679 - accuracy: 0.9236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:19:02.248268: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 26s 71ms/step - loss: 0.2683 - accuracy: 0.9235 - val_loss: 0.1356 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.9436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:19:27.435929: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 25s 70ms/step - loss: 0.2029 - accuracy: 0.9436 - val_loss: 0.1153 - val_accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "114/361 [========>.....................] - ETA: 12s - loss: 0.2025 - accuracy: 0.9452\n",
      "Epoch 00006: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 71ms/step - loss: 0.1934 - accuracy: 0.9475 - val_loss: 0.1396 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "361/361 [==============================] - 25s 70ms/step - loss: 0.1568 - accuracy: 0.9568 - val_loss: 0.0825 - val_accuracy: 0.9755 - lr: 0.0010\n",
      "Epoch 8/100\n",
      " 32/361 [=>............................] - ETA: 16s - loss: 0.1415 - accuracy: 0.9634\n",
      "Epoch 00008: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 71ms/step - loss: 0.1439 - accuracy: 0.9598 - val_loss: 0.0921 - val_accuracy: 0.9746 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "311/361 [========================>.....] - ETA: 2s - loss: 0.1331 - accuracy: 0.9630\n",
      "Epoch 00009: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 71ms/step - loss: 0.1332 - accuracy: 0.9629 - val_loss: 0.0641 - val_accuracy: 0.9822 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "361/361 [==============================] - 25s 70ms/step - loss: 0.1240 - accuracy: 0.9669 - val_loss: 0.0985 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "229/361 [==================>...........] - ETA: 6s - loss: 0.1227 - accuracy: 0.9673\n",
      "Epoch 00011: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 72ms/step - loss: 0.1172 - accuracy: 0.9681 - val_loss: 0.0548 - val_accuracy: 0.9848 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "361/361 [==============================] - 25s 70ms/step - loss: 0.1088 - accuracy: 0.9707 - val_loss: 0.0774 - val_accuracy: 0.9793 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "146/361 [===========>..................] - ETA: 11s - loss: 0.1009 - accuracy: 0.9714\n",
      "Epoch 00013: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 71ms/step - loss: 0.1007 - accuracy: 0.9720 - val_loss: 0.0623 - val_accuracy: 0.9822 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "361/361 [==============================] - 25s 69ms/step - loss: 0.0945 - accuracy: 0.9746 - val_loss: 0.0646 - val_accuracy: 0.9825 - lr: 0.0010\n",
      "Epoch 15/100\n",
      " 65/361 [====>.........................] - ETA: 16s - loss: 0.0913 - accuracy: 0.9757\n",
      "Epoch 00015: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 73ms/step - loss: 0.0837 - accuracy: 0.9767 - val_loss: 0.0512 - val_accuracy: 0.9848 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "344/361 [===========================>..] - ETA: 0s - loss: 0.0850 - accuracy: 0.9773\n",
      "Epoch 00016: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 71ms/step - loss: 0.0860 - accuracy: 0.9771 - val_loss: 0.0724 - val_accuracy: 0.9817 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "361/361 [==============================] - 25s 70ms/step - loss: 0.0897 - accuracy: 0.9768 - val_loss: 0.0679 - val_accuracy: 0.9839 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "261/361 [====================>.........] - ETA: 5s - loss: 0.0777 - accuracy: 0.9795\n",
      "Epoch 00018: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 71ms/step - loss: 0.0777 - accuracy: 0.9796 - val_loss: 0.0473 - val_accuracy: 0.9862 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "361/361 [==============================] - 25s 70ms/step - loss: 0.0838 - accuracy: 0.9785 - val_loss: 0.0474 - val_accuracy: 0.9858 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "180/361 [=============>................] - ETA: 9s - loss: 0.0754 - accuracy: 0.9812\n",
      "Epoch 00020: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 71ms/step - loss: 0.0752 - accuracy: 0.9808 - val_loss: 0.0866 - val_accuracy: 0.9776 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "361/361 [==============================] - 25s 69ms/step - loss: 0.0751 - accuracy: 0.9804 - val_loss: 0.0729 - val_accuracy: 0.9801 - lr: 0.0010\n",
      "Epoch 22/100\n",
      " 98/361 [=======>......................] - ETA: 13s - loss: 0.0685 - accuracy: 0.9823\n",
      "Epoch 00022: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 72ms/step - loss: 0.0748 - accuracy: 0.9810 - val_loss: 0.0497 - val_accuracy: 0.9876 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "361/361 [==============================] - 25s 70ms/step - loss: 0.0753 - accuracy: 0.9812 - val_loss: 0.0390 - val_accuracy: 0.9893 - lr: 0.0010\n",
      "Epoch 24/100\n",
      " 15/361 [>.............................] - ETA: 17s - loss: 0.0561 - accuracy: 0.9844\n",
      "Epoch 00024: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 71ms/step - loss: 0.0607 - accuracy: 0.9844 - val_loss: 0.0391 - val_accuracy: 0.9888 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "295/361 [=======================>......] - ETA: 3s - loss: 0.0603 - accuracy: 0.9848\n",
      "Epoch 00025: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 26s 72ms/step - loss: 0.0627 - accuracy: 0.9842 - val_loss: 0.0721 - val_accuracy: 0.9807 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "361/361 [==============================] - 25s 70ms/step - loss: 0.0567 - accuracy: 0.9855 - val_loss: 0.0609 - val_accuracy: 0.9855 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "212/361 [================>.............] - ETA: 7s - loss: 0.0543 - accuracy: 0.9863\n",
      "Epoch 00027: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 24s 65ms/step - loss: 0.0534 - accuracy: 0.9860 - val_loss: 0.0296 - val_accuracy: 0.9918 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "361/361 [==============================] - 23s 63ms/step - loss: 0.0589 - accuracy: 0.9847 - val_loss: 0.0355 - val_accuracy: 0.9902 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "130/361 [=========>....................] - ETA: 11s - loss: 0.0517 - accuracy: 0.9863\n",
      "Epoch 00029: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 24s 66ms/step - loss: 0.0521 - accuracy: 0.9866 - val_loss: 0.0383 - val_accuracy: 0.9895 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "361/361 [==============================] - 23s 64ms/step - loss: 0.0516 - accuracy: 0.9863 - val_loss: 0.0416 - val_accuracy: 0.9893 - lr: 0.0010\n",
      "Epoch 31/100\n",
      " 49/361 [===>..........................] - ETA: 15s - loss: 0.0594 - accuracy: 0.9864\n",
      "Epoch 00031: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 23s 65ms/step - loss: 0.0526 - accuracy: 0.9864 - val_loss: 0.0417 - val_accuracy: 0.9877 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "327/361 [==========================>...] - ETA: 1s - loss: 0.0548 - accuracy: 0.9864\n",
      "Epoch 00032: saving model to ckpt_app_training/cp.ckpt\n",
      "361/361 [==============================] - 24s 66ms/step - loss: 0.0558 - accuracy: 0.9862 - val_loss: 0.0346 - val_accuracy: 0.9903 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2713d181c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, \n",
    "          validation_data=val_images,\n",
    "          epochs=EPOCH,\n",
    "          callbacks=callback_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:30:45.996053: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/app_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(entire_model_s_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(entire_model_s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 5s 10ms/step - loss: 0.4442 - accuracy: 0.9341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44423216581344604, 0.9340956211090088]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload weight by checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f271861b670>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4039 - accuracy: 0.9204\n",
      "Restored model, accuracy: 92.04%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASLT",
   "language": "python",
   "name": "aslt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
