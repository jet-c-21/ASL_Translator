{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Normal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:43:55.383266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:55.395762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:55.396774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asl_model import *\n",
    "\n",
    "TRAIN_DIR = 'DATASET_A_AP/train'\n",
    "TEST_DIR = 'DATASET_A_AP/test'\n",
    "\n",
    "BATCH = 128\n",
    "EPOCH = 100\n",
    "\n",
    "model_func = get_stn_a_model_8\n",
    "\n",
    "checkpoint_path = \"ckpt_stl_training/cp.ckpt\"\n",
    "tb_log_dir = 'stl-logs/'\n",
    "entire_model_s_path = 'saved_model/stl_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert folder to dataframe of images' paths & labels\n",
    "def get_paths_labels(path, allowed_extension=\"jpg\"):\n",
    "        global Path\n",
    "        images_dir = Path(path)\n",
    "        \n",
    "        filepaths = pd.Series((images_dir.glob(fr'**/*.{allowed_extension}'))).astype(str)\n",
    "        filepaths.name = \"path\"\n",
    "        \n",
    "        labels = filepaths.str.split(\"/\")[:].str[-2]\n",
    "        labels.name = \"label\"\n",
    "\n",
    "        # Concatenate filepaths and labels\n",
    "        df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "        # Shuffle the DataFrame and reset index\n",
    "        df = df.sample(frac=1).reset_index(drop = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_paths_labels(TRAIN_DIR)\n",
    "test_df = get_paths_labels(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46174 validated image filenames belonging to 26 classes.\n",
      "Found 11543 validated image filenames belonging to 26 classes.\n",
      "Found 14430 validated image filenames belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=0.2,\n",
    "                                    rescale=1. / 255.,\n",
    "                                    zoom_range=0.1,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.1,)\n",
    "\n",
    "test_generator = ImageDataGenerator(rescale=1. / 255.)\n",
    "\n",
    "train_images = data_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_images = data_generator.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    batch_size=BATCH,\n",
    "    shuffle=True,\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    # batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"ckpt_normal_training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=2, \n",
    "    save_weights_only=True,\n",
    "    # save_best_only=True,\n",
    "    save_freq=5*BATCH\n",
    ")\n",
    "\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau()\n",
    "\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_log_dir, histogram_freq=1)\n",
    "\n",
    "callback_ls = [\n",
    "    es_callback, \n",
    "    reduce_lr_callback, \n",
    "    cp_callback,\n",
    "    tb_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = model_func()\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:43:56.899027: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-23 01:43:56.900100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:56.900703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:56.901203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:57.333403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:57.333941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:57.334440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-23 01:43:57.334919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8061 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:43:59.652230: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - ETA: 0s - loss: 1.8146 - accuracy: 0.5783"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:44:23.816032: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 27s 68ms/step - loss: 1.8146 - accuracy: 0.5783 - val_loss: 3.0955 - val_accuracy: 0.1262 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "278/361 [======================>.......] - ETA: 4s - loss: 0.7818 - accuracy: 0.7924\n",
      "Epoch 00002: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.7393 - accuracy: 0.8046"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:44:48.281006: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 24s 68ms/step - loss: 0.7393 - accuracy: 0.8046 - val_loss: 0.3858 - val_accuracy: 0.8998 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "360/361 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.8795"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:45:12.359246: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 24s 67ms/step - loss: 0.4602 - accuracy: 0.8795 - val_loss: 0.2145 - val_accuracy: 0.9455 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "195/361 [===============>..............] - ETA: 8s - loss: 0.3465 - accuracy: 0.9075\n",
      "Epoch 00004: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.9119"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:45:36.975589: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 25s 68ms/step - loss: 0.3273 - accuracy: 0.9119 - val_loss: 0.1384 - val_accuracy: 0.9669 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "361/361 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:46:01.036176: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 7612661760 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361/361 [==============================] - 24s 67ms/step - loss: 0.2513 - accuracy: 0.9322 - val_loss: 0.1592 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "114/361 [========>.....................] - ETA: 12s - loss: 0.2121 - accuracy: 0.9425\n",
      "Epoch 00006: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 24s 68ms/step - loss: 0.1924 - accuracy: 0.9476 - val_loss: 0.0871 - val_accuracy: 0.9776 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "361/361 [==============================] - 24s 67ms/step - loss: 0.1635 - accuracy: 0.9552 - val_loss: 0.0784 - val_accuracy: 0.9802 - lr: 0.0010\n",
      "Epoch 8/100\n",
      " 32/361 [=>............................] - ETA: 16s - loss: 0.1405 - accuracy: 0.9595\n",
      "Epoch 00008: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 68ms/step - loss: 0.1422 - accuracy: 0.9599 - val_loss: 0.0765 - val_accuracy: 0.9822 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "311/361 [========================>.....] - ETA: 2s - loss: 0.1252 - accuracy: 0.9658\n",
      "Epoch 00009: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 68ms/step - loss: 0.1256 - accuracy: 0.9653 - val_loss: 0.0990 - val_accuracy: 0.9757 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "361/361 [==============================] - 24s 68ms/step - loss: 0.1146 - accuracy: 0.9691 - val_loss: 0.0606 - val_accuracy: 0.9838 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "229/361 [==================>...........] - ETA: 6s - loss: 0.0962 - accuracy: 0.9732\n",
      "Epoch 00011: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 69ms/step - loss: 0.0986 - accuracy: 0.9733 - val_loss: 0.0660 - val_accuracy: 0.9844 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "361/361 [==============================] - 24s 67ms/step - loss: 0.0984 - accuracy: 0.9732 - val_loss: 0.0508 - val_accuracy: 0.9869 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "147/361 [===========>..................] - ETA: 10s - loss: 0.0841 - accuracy: 0.9758\n",
      "Epoch 00013: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 69ms/step - loss: 0.0858 - accuracy: 0.9765 - val_loss: 0.0567 - val_accuracy: 0.9848 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "361/361 [==============================] - 24s 66ms/step - loss: 0.0847 - accuracy: 0.9776 - val_loss: 0.0667 - val_accuracy: 0.9841 - lr: 0.0010\n",
      "Epoch 15/100\n",
      " 65/361 [====>.........................] - ETA: 14s - loss: 0.0906 - accuracy: 0.9781\n",
      "Epoch 00015: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 69ms/step - loss: 0.0842 - accuracy: 0.9789 - val_loss: 0.0461 - val_accuracy: 0.9886 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "344/361 [===========================>..] - ETA: 0s - loss: 0.0724 - accuracy: 0.9807\n",
      "Epoch 00016: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 68ms/step - loss: 0.0732 - accuracy: 0.9806 - val_loss: 0.0724 - val_accuracy: 0.9833 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "361/361 [==============================] - 24s 67ms/step - loss: 0.0765 - accuracy: 0.9797 - val_loss: 0.0391 - val_accuracy: 0.9899 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "262/361 [====================>.........] - ETA: 4s - loss: 0.0620 - accuracy: 0.9828\n",
      "Epoch 00018: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 68ms/step - loss: 0.0654 - accuracy: 0.9822 - val_loss: 0.0495 - val_accuracy: 0.9879 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "361/361 [==============================] - 24s 66ms/step - loss: 0.0631 - accuracy: 0.9840 - val_loss: 0.0491 - val_accuracy: 0.9880 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "180/361 [=============>................] - ETA: 9s - loss: 0.0611 - accuracy: 0.9840\n",
      "Epoch 00020: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 68ms/step - loss: 0.0591 - accuracy: 0.9847 - val_loss: 0.0403 - val_accuracy: 0.9901 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "361/361 [==============================] - 24s 67ms/step - loss: 0.0577 - accuracy: 0.9849 - val_loss: 0.0499 - val_accuracy: 0.9895 - lr: 0.0010\n",
      "Epoch 22/100\n",
      " 97/361 [=======>......................] - ETA: 13s - loss: 0.0564 - accuracy: 0.9862\n",
      "Epoch 00022: saving model to ckpt_stl_training/cp.ckpt\n",
      "361/361 [==============================] - 25s 68ms/step - loss: 0.0545 - accuracy: 0.9856 - val_loss: 0.0413 - val_accuracy: 0.9906 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f910a201bb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, \n",
    "          validation_data=val_images,\n",
    "          epochs=EPOCH,\n",
    "          callbacks=callback_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-23 01:52:59.772417: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/stl_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(entire_model_s_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(entire_model_s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 13s 24ms/step - loss: 0.4414 - accuracy: 0.9060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4413565993309021, 0.9060291051864624]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.evaluate(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reload weight by checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f910a4cd370>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "451/451 [==============================] - 6s 11ms/step - loss: 0.5512 - accuracy: 0.9044\n",
      "Restored model, accuracy: 90.44%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = new_model.evaluate(test_images)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASLT",
   "language": "python",
   "name": "aslt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
