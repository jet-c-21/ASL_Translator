{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Normal Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from string import ascii_uppercase\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TEST_DIR = 'DATASET_A_AP/test'\n",
    "\n",
    "# args\n",
    "entire_model_s_path = 'saved_model/normal_model' \n",
    "model_prefix = 'normal-model'\n",
    "\n",
    "\n",
    "chart_s_dir = 'charts'\n",
    "\n",
    "fc_chart_name = f\"{model_prefix}-alphabet-failed-predict-count-plotly.jpg\"\n",
    "fc_chart_s_path = f\"{chart_s_dir}/{fc_chart_name}\"\n",
    "\n",
    "fc_chart_mpl_name = f\"{model_prefix}-alphabet-failed-predict-count-matplotlib.jpg\"\n",
    "fc_chart_mpl_s_path = f\"{chart_s_dir}/{fc_chart_mpl_name}\"\n",
    "\n",
    "acc_chart_name = f\"{model_prefix}-alphabet-acc-plotly.jpg\"\n",
    "acc_chart_s_path = f\"{chart_s_dir}/{acc_chart_name}\"\n",
    "\n",
    "acc_chart_mpl_name = f\"{model_prefix}-alphabet-acc-matplotlib.jpg\"\n",
    "acc_chart_mpl_s_path = f\"{chart_s_dir}/{acc_chart_mpl_name}\"\n",
    "\n",
    "cm_hs_name = f\"{model_prefix}-confusion-matrix-heat-map.jpg\"\n",
    "cm_hm_s_path = f\"{chart_s_dir}/{cm_hs_name}\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert folder to dataframe of images' paths & labels\n",
    "def get_paths_labels(path, allowed_extension=\"jpg\"):\n",
    "        Path\n",
    "        images_dir = Path(path)\n",
    "        \n",
    "        filepaths = pd.Series((images_dir.glob(fr'**/*.{allowed_extension}'))).astype(str)\n",
    "        filepaths.name = \"path\"\n",
    "        \n",
    "        labels = filepaths.str.split(\"/\")[:].str[-2]\n",
    "        labels.name = \"label\"\n",
    "\n",
    "        # Concatenate filepaths and labels\n",
    "        df = pd.concat([filepaths, labels], axis=1)\n",
    "\n",
    "        # Shuffle the DataFrame and reset index\n",
    "        df = df.sample(frac=1).reset_index(drop = True)\n",
    "        return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = get_paths_labels(TEST_DIR)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1. / 255.)\n",
    "\n",
    "test_images = test_generator.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='path',\n",
    "    y_col='label',\n",
    "    target_size=(28, 28),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    # batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "fc_chart_name = f\"{model_prefix}-alphabet-failed-predict-count-plotly.jpg\"\n",
    "fc_chart_s_path = f\"{chart_s_dir}/{fc_chart_name}\"# reload the entire model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(entire_model_s_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Review Accuracy and Loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_images)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### View each class prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alphabet_ls = list(ascii_uppercase)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_alphabet_idxs = np.argmax(model.predict(test_images), -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_res = [alphabet_ls[i] for i in pred_alphabet_idxs]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ground_truths = [alphabet_ls[i] for i in test_images.labels]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_c_per_cls = 555\n",
    "\n",
    "def get_empty_afp_dict():\n",
    "    result = dict()\n",
    "    for a in alphabet_ls:\n",
    "        result[a] = 0\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Source code credit for this function: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\n",
    "def print_confusion_matrix_heat_map(confusion_matrix, class_names, figsize = (26,26), fontsize=14, plt_s_path=None):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('Truth')\n",
    "    plt.xlabel('Prediction')\n",
    "    \n",
    "    if plt_s_path:\n",
    "        plt.savefig(plt_s_path, dpi=300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "afp_dict = get_empty_afp_dict()\n",
    "for pred_cls, gt in zip(pred_res, ground_truths):\n",
    "    if pred_cls != gt:\n",
    "        if gt in afp_dict.keys(): # gt should be the key, not pred_cls\n",
    "            afp_dict[gt] += 1\n",
    "        else:\n",
    "            afp_dict[gt] = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "afp_df = pd.DataFrame(\n",
    "    list(afp_dict.items()),\n",
    "    columns=['alphabet', 'fc'],\n",
    ")\n",
    "\n",
    "afp_df['fcr'] = afp_df['fc'] / data_c_per_cls\n",
    "afp_df['acc'] = 1 - afp_df['fcr']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Failed Prediciton Count View"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotly"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Failed Prediction Count of Each Alphabet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    afp_df,\n",
    "    x='alphabet', \n",
    "    y='fc',\n",
    "    \n",
    "    labels={\n",
    "        \"alphabet\": \"Alphabet\",\n",
    "        \"fc\": \"Failed Prediction Count\",\n",
    "    },\n",
    "    title='Failed Prediction Count of Each Alphabet',\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(fc_chart_s_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Accuarcy of Each Alphabet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    afp_df,\n",
    "    x='alphabet', \n",
    "    y='acc',\n",
    "    \n",
    "    labels={\n",
    "        \"alphabet\": \"Alphabet\",\n",
    "        \"acc\": \"Accuaracy\",\n",
    "    },\n",
    "    \n",
    "    title='Accuarcy of Each Alphabet',\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(acc_chart_s_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confusion Matrix Heat Map and F1 Report"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ground_truths, pred_res)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print_confusion_matrix_heat_map(cm, alphabet_ls, plt_s_path=cm_hm_s_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf_report = classification_report(ground_truths, pred_res)\n",
    "print(clf_report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Other Chart Tools"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### matplotlib"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alphabets = afp_df['alphabet'].values\n",
    "fcs = afp_df['fc'].values\n",
    "x = np.arange(len(alphabets))\n",
    "plt.bar(x, fcs)\n",
    "plt.xticks(x, alphabets)\n",
    "plt.xlabel('Alphabet')\n",
    "plt.ylabel('Failed Prediction Count')\n",
    "plt.title('Failed Prediction Count of Each Alphabet')\n",
    "plt.savefig(fc_chart_mpl_s_path, dpi=300)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "alphabets = afp_df['alphabet'].values\n",
    "fcs = afp_df['acc'].values\n",
    "x = np.arange(len(alphabets))\n",
    "plt.bar(x, fcs)\n",
    "plt.xticks(x, alphabets)\n",
    "plt.xlabel('Alphabet')\n",
    "plt.ylabel('Accuaracy')\n",
    "plt.title('Accuarcy of Each Alphabet')\n",
    "plt.savefig(acc_chart_mpl_s_path, dpi=300)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASLT",
   "language": "python",
   "name": "aslt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}